---
title: "ACIC 2016 simulations"
subtitle: "Dorie et al. (2019)"
format: pdf
---

```{r}
# Load packages
# devtools::install_github("tlverse/tlverse")
#library(dplyr)
library(data.table)
library(estimatr) # Fast regression and Lin
library(gKRLS) # Kernel regression
library(tlverse)
library(sl3) # SuperLearner
library(tmle3) # Targeted Learning

# For parallel processing (not working)
#library(future)
#ncores <- availableCores()-1
#plan(multicore, workers = ncores)

# Define path for data
path <- "/Users/pablogeraldo/Documents/data_cf_all/"

# Load the covariates
covs <- data.table::fread(paste0(path,"x.csv"),
                          stringsAsFactors = TRUE)

# For now, just for testing, load one iteration of the outcome
outcomes <- data.table::fread(paste0(path,"1/zymu_13.csv")) 

```

Here we report the performance of the prognostic propensity score in estimating treatment effects according to the simulations in Dorie et al. (2019), corresponding to the 2016 data competition at the American Causal Inference Conference.

## Simulation setup

We will use the first 20 DGPs (out of 77 different DGPs), corresponding to the "do it yourself" component of the 2016 ACIC competition.

### Premilinaries

```{r}
# Create container for the simulation results
# dim: [n_estimators x n_sims x n_dgps] by [n_metrics]

# Define number of simulations and number of GDPs to be tested
n_sims <- 100
n_dgps <- 20

# Define estimators and metrics to be used
estimators <- c("Coeff:Linear","Coeff:Linear:Lin",
                "Bal:PSM:Logit","Bal:PSM:Lasso","Bal:PSM:xgboost","Bal:PSM:Krls","Bal:PSM:SL",
                "Bal:IPW:Logit","Bal:IPW:Lasso","Bal:IPW:xgboost","Bal:IPW:Krls","Bal:IPW:SL",
                "Bal:Ebal:raw", "Bal:Ebal:expand",#"Bal:Kernel",
                "Bal:Y0:Lin","Bal:Y0:Lasso","Bal:Y0:xgboost","Bal:Y0:Krls","Bal:Y0:SL",
                "G-comp:one:Lasso","G-comp:one:xgboost","G-comp:one:Krls","G-comp:one:SL",
                "G-comp:cross:Lasso","G-comp:cross:xgboost","G-comp:cross:Krls","G-comp:cross:SL",
                "DR:AIPW:LogLin","DR:AIPW:xgboost","DR:AIPW:grf","DR:AIPW:Krls","DR:AIPW:SL",
                "DR:TMLE:LogLin","DR:TMLE:xgboost","DR:TMLE:grf","DR:TMLE:Krls","DR:TMLE:SL",
                "DR:DML:LogLin","DR:DML:xgboost","DR:DML:Krls","DR:DML:SL",
                "PPSM:LinLin","PPSM:LinLog","PPSM:xgboost","PPSM:Krls","PPSM:SL",
                "IPPW:LinLin","IPPW:LinLog","IPPW:xgboost","IPPW:Krls","IPPW:SL"
)
metrics <- c("DGP","Simulation","Estimator","Bias", "RMSE", "MAE", "RESS", "Balance", "Time")

# Simulation results storage
results <- matrix(nrow = n_sims * n_dgps * length(estimators),
                  ncol = length(metrics)) |> as.data.table()
names(results) <- metrics

###########################
### --- SIMULATIONS --- ### 
###########################

# Create empty list to store data
data <- list()

# Iterate over different DGPs 
# (1:20), corresponding to the do-it-yourself part of the competition
dgp <- 1:n_dgps

for(i in dgp){
  
  # Combine different simulations of same DGP
  # (1:100), keep sim identifier
  
  # First, capture the list of files to be used
  file_list <- 
    list.files(paste0(path,"1"), # Switch to the i later
               pattern = "*.csv", 
               ignore.case = TRUE,
               full.names = FALSE)
  
  for(j in file_list){
    
    data[[j]] <- data.table::fread(
      file = paste0(path,"1/",j)
    )[, sim_id := j] # Add identifier to data
    
  }
  
  # Combine the list into a single data frame
  data <- data.table::rbindlist(data)
```
  
  
### Building blocks
  
```{r}
  # Estimate the models to later compute treatment effects: 
  # Propensity scores and outcome models
  
  # First, combine outcome and covs in a single data
  data <- cbind(outcomes, covs)
  data <- data |> dplyr::mutate(y = ifelse(z==0, y0, y1))
  
  # Then, benchmark estimates
  ate <- mean(data$y1 - data$y0)
  dim <- mean(data$y[data$z==1]) - mean(data$y[data$z==0])
  data$z <- as.factor(data$z)
  
  # Then, for the SuperLearner, instante the models to be used
  
  ######################
  # Instantiate learners to be used
  ######################
  
  # Mean model
  lrn_mean <- Lrnr_mean$new()
  
  # Unregularized linear model, main terms
  lrn_glm <- Lrnr_glm$new()
  
  # Regularized regression (lasso, elastic net, and ridge)
  lrn_lasso <- Lrnr_glmnet$new(alpha = 0)
  lrn_en025 <- Lrnr_glmnet$new(alpha = 0.25)
  lrn_en050 <- Lrnr_glmnet$new(alpha = 0.5)
  lrn_en075 <- Lrnr_glmnet$new(alpha = 0.75)
  lrn_ridge <- Lrnr_glmnet$new(alpha = 1)
  
  # Additional, more flexible learners
  lrn_pspl <- Lrnr_polspline$new() # polynomial splines
  lrn_earth <- Lrnr_earth$new() # multivariate adaptive regression splines
  #lrn_hal <- Lrnr_hal9001$new() # highly adaptive lasso (very slow!)
  
  # Tree-based methods
  lrn_ranger <- Lrnr_ranger$new()
  lrn_xgb <- Lrnr_xgboost$new()
  #lrn_grf <- Lrnr_grf$new() # makes the SL fail (?)
  
  # Add some extra learners
  lrn_gam <- Lrnr_gam$new()
  lrn_bayesglm <- Lrnr_bayesglm$new()
  
  # Input formula for the krls regression
    fml <- 
    as.formula(
      paste("y ~",
            paste(paste(c("s(z +"),
                        paste(names(covs), collapse = "+")),
                  c(", bs = \"gKRLS\")"))))
    lrn_krls <- Lrnr_gam$new(fml)
  
  ########################
  # Create learners stack
  ########################
  
  stack <- Stack$new(
    "mean" = lrn_mean, "glm" = lrn_glm, 
    "lasso" = lrn_lasso, "ridge" = lrn_ridge,
    "en025" = lrn_en025, "en050" = lrn_en050, "en075" = lrn_en075, 
    "polspline" = lrn_pspl, "earth" = lrn_earth, 
    "ranger" = lrn_ranger, "xgboost" = lrn_xgb,
    "gam" = lrn_gam, "bglm" = lrn_bayesglm, "krls" = lrn_krls
  )
  
  #####################
  # Instantiate the meta-learners
  #####################
  
  # Non-negative least squares
  sl <- Lrnr_sl$new(learners = stack,
                    keep_extra = TRUE,
                    metalearner = Lrnr_nnls$new()
  )
  
  ######################
  ## Propensity score ##
  ######################
  
  # Estimators outside the SL: lin, grf, kernel
  
  # KRLS pending until I figure this out
  # Lin not sure it makes sense for pscore
  
  
  
  # For the SuperLearner, first define the tasks, then train
  
  # Task: Propensity score estimation (predict treatment given covariates)
  task_ps <- sl3_Task$new(
    data = data,
    outcome = "z",
    outcome_type = "binomial",
    covariates = names(covs)
  )
    
    # Single regression models (predict Y using covariates)
  task_y <- sl3_Task$new(
    data = data,
    outcome = "y",
    outcome_type = "continuous",
    covariates = c("z", names(covs))
  )
  
  # Separate regression models (predict Y0, Y1 using covariates)
  task_y0 <- sl3_Task$new(
    data = subset(data, z == 0),
    outcome = "y",
    outcome_type = "continuous",
    covariates = names(covs)
  )
  
  task_y1 <- sl3_Task$new(
    data = subset(data, z == 1),
    outcome = "y",
    outcome_type = "continuous",
    covariates = names(covs)
  )
  
  # PO imputation tasks  
  task_y0hat <- sl3_Task$new(
    data = data[,z:=0],
    covariates = 
  )  
    
  
  # Train learners
  fit_gKRLS <- mgcv::gam(fml, data = data)
  fit_gKRLS
  calculate_effects(fit_gKRLS, variables = "z")
  
  set.seed(24500-03)
  start_time <- proc.time()
  
  sl_y <- sl$train(task = task_y)
  #krls_y <- lrn_krls$train(task = task_y)
  
  runtime <- proc.time() - start_time
  runtime
  
  # Logistic regression
  
  ps_lm <- ()
  
  # LASSO
  
  ps_lasso <- ()
  
  # Random forest
  
  ps_grf <- ()
  
  # Kernel regression
  
  ps_krls <- ()

  
  
  
  
  
  
  # Train (test time for 1 iteration)
  
  set.seed(24500-03)
  start_time <- proc.time()
  
  sl_fit <- sl$train(task = task_y)
  #stack_fit <- stack$train(task = task_y)
  
  runtime <- proc.time() - start_time
  runtime
  
  # Obtaining predictions from the stack and SL
  
  yhat_sl <- sl_fit$predcit(task = task_y) # General SL predictions
  yhat_lasso <- sl_fit$learner_fits$Lrnr_glmnet_NULL_deviance_10_0_100_TRUE_FALSE$predict()
  
  
  ####################
  ## Outcome models ##
  ####################
  
  # Linear regression
  
  y0_lm <- ()
  y1_lm <- ()
  
  y0_lin <- ()
  y1_lin <- ()
  
  # LASSO
  
  y0_lasso
  y1_lasso
  
  # Random forest
  
  y0_grf
  y1_grf
  
  # Kernel regression
  
  y0_krls
  y1_krls
  
  
  
  ##########################
  ### --- ESTIMATORS --- ###
  ##########################
  
  #############################
  ## Regression Coefficients ##
  #############################
  
  ###################
  ## G-Computation ##
  ###################
  
  ##############
  ## Matching ##
  ##############
  
  ###############
  ## Weighting ##
  ###############
  
  ###########################
  ## Augmented  estimators ##
  ###########################
  
  # Augmented-IPW
  
  # TMLE
  
  # DML
  
  #################################
  ## Prognostic Propensity score ##
  #################################
  
  # PPS-Matching (logit/lasso/forest/krls)
  
  # PPS-Weighting (logit/lasso/forest/krls)
  
  # Y0-weighting (logit/lasso/forest/krls)
  
}
```

### Propensity score

```{r}
caca
```


### Outcome models

```{r}
caca
```


### Treatment effect estimation

```{r}
# The estimators we are going to test are the following
# Balance covariate alone: IPW, PS-matching, Ebal, Tfbal
# Outcome model alone: Linear regression, Lin, GRF, Kbal
# DR models: AIPW, TMLE, DML
# Proposed estimators: 
# 1) Prognostic Balance (E(Y0))
# 2) Prognostic Propensity Score (E(D|Y0)) Balance
# 3) Prognostic 


# DR: Generalized random forest : causal forest
grf <- causal_forest(X = data[covs], Y = data$y, W = data$z)
aipw_grf <- average_treatment_effect(grf, target.sample = "all", method = "AIPW")
tmle_grf <- average_treatment_effect(grf, target.sample = "all", method = "TMLE")

# Save table with missing cases
data.table::fwrite(data,
                   file = paste0(path_results, "/table_data.csv"),
                   append = TRUE)

```
