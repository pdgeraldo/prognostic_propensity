---
title: "ACIC 2016 simulations"
subtitle: "Dorie et al. (2019)"
format: pdf
---

```{r}
# Load packages
# devtools::install_github("tlverse/tlverse")
#library(dplyr)
library(data.table)
library(estimatr) # Fast regression and Lin
library(gKRLS) # Kernel regression
library(tlverse)
library(sl3) # SuperLearner
library(tmle3) # Targeted Learning

# For parallel processing (not working)
#library(future)
#ncores <- availableCores()-1
#plan(multicore, workers = ncores)

# Define path for data
path <- "/Users/pablogeraldo/Documents/data_cf_all/"

# Load the covariates
covs <- data.table::fread(paste0(path,"x.csv"),
                          stringsAsFactors = TRUE)

# For now, just for testing, load one iteration of the outcome
outcomes <- data.table::fread(paste0(path,"1/zymu_13.csv")) 

# First, combine outcome and covs in a single data
data <- cbind(outcomes, covs)
data <- data |> dplyr::mutate(y = ifelse(z==0, y0, y1))

# Then, benchmark estimates
ate <- mean(data$y1 - data$y0)
dim <- mean(data$y[data$z==1]) - mean(data$y[data$z==0])

```

Here we report the performance of the prognostic propensity score in estimating treatment effects according to the simulations in Dorie et al. (2019), corresponding to the 2016 data competition at the American Causal Inference Conference.

## Simulation setup

We will use the first 20 DGPs (out of 77 different DGPs), corresponding to the "do it yourself" component of the 2016 ACIC competition.

### Premilinaries

We first create the container data.frame to store results across simulations.

```{r}
##########
# STORAGE: create the data.frame to save results
##########

# Create container for the simulation results
# dim: [n_estimators x n_sims x n_dgps] by [n_metrics]

# Define number of simulations and number of GDPs to be tested
n_sims <- 100
n_dgps <- 20

# Define estimators and metrics to be used
estimators <- c("Diff-in-means","Coeff:Linear","Coeff:Linear:Lin",
                "Bal:PSM:Logit","Bal:PSM:Lasso","Bal:PSM:xgboost",
                "Bal:PSM:Krls","Bal:PSM:SL",
                "Bal:IPW:Logit","Bal:IPW:Lasso","Bal:IPW:xgboost",
                "Bal:IPW:Krls","Bal:IPW:SL",
                "Bal:Ebal:raw", "Bal:Ebal:expand",
                "Bal:Y0:Lin","Bal:Y0:Lasso","Bal:Y0:xgboost",
                "Bal:Y0:Krls","Bal:Y0:SL",
                "G-comp:single:Lasso","G-comp:single:xgboost","G-comp:single:earth",
                "G-comp:single:Krls","G-comp:single:SL",
                "G-comp:cross:Lasso","G-comp:cross:xgboost","G-comp:cross:earth",
                "G-comp:cross:Krls","G-comp:cross:SL",
                "DR:AIPW:LogLin","DR:AIPW:xgboost","DR:AIPW:grf",
                "DR:AIPW:Krls","DR:AIPW:SL",
                "DR:TMLE:LogLin","DR:TMLE:xgboost","DR:TMLE:grf",
                "DR:TMLE:Krls","DR:TMLE:SL",
                "DR:DML:LogLin","DR:DML:xgboost",
                "DR:DML:Krls","DR:DML:SL",
                "PPSM:LinLin","PPSM:LinLog","PPSM:xgboost",
                "PPSM:Krls","PPSM:SL",
                "IPPW:LinLin","IPPW:LinLog","IPPW:xgboost",
                "IPPW:Krls","IPPW:SL"
)
metrics <- c("DGP","Simulation","Estimator","Bias","RMSE","MAE","RESS","Balance","Time")

# Simulation results storage
results <- matrix(NA_real_,
                  nrow = n_sims * n_dgps * length(estimators),
                  ncol = length(metrics)) |> data.table()
names(results) <- metrics
results[, ':='(DGP = rep(1:n_dgps, each = n_sims*length(estimators)),
               Simulation = rep(1:n_sims, each = length(estimators), times = n_dgps),
               Estimator = rep(estimators, times = n_dgps*n_sims))]

```

Now setup the full simulation

```{r, warning=FALSE}
###########################
### --- SIMULATIONS --- ### 
###########################

# For reproducibility
set.seed(24500-03)

# Iterate over different DGPs 
# (1:20), corresponding to the do-it-yourself part of the competition
dgp <- 1:n_dgps
# For now
dgp <- 1:2

for(i in dgp){
  
  # First, capture the list of files in the directory
  file_list <- 
    list.files(paste0(path,i), # Switch to the i later
               pattern = "*.csv", 
               ignore.case = TRUE,
               full.names = FALSE)
  
  #for(j in 1:length(file_list)){
  for(j in 1:5){
    
    #Keep track of iterations
    #print(j)
    #print(paste0(path,i,"/",file_list[j]))
    
    # Create data.frame combining covariates and outcomes
    data <- cbind(
      data.table::fread(
        file = paste0(path,i,"/",file_list[j])), covs
    )[, y := ifelse(z==0, y0, y1)] # Create observed outcome (from switching equation)
    
    # Create data.frames for prediction (g-comp)
    dataZ0 <- copy(data)[,z:=0]
    dataZ1 <- copy(data)[,z:=1]
    
    # Benchmark estimates
    ate <- mean(data$y1 - data$y0)
    dim <- mean(data$y[data$z==1]) - mean(data$y[data$z==0])
    
    # Store diff-in-means as reference
    results[Estimator == 'Diff-in-means' & 
              DGP == i & Simulation == j ,'Bias'] <- dim-ate
    
    
    ##############################
    ### --- OUTCOME MODELS --- ### 
    ##############################
    
    ###################
    ### OUTCOME MODELS: Stand-alone
    ##################
    # Let's start with the stand alone estimators
    
    #################
    # Lin estimator #
    #################
    
    # Run model
    coeff_lin <- 
      estimatr::lm_lin(y~z, covariates = cobalt::f.build("", names(covs)), data = data)
    
    # Store results
    results[Estimator == 'Coeff:Linear:Lin' & 
              DGP == i & Simulation == j ,'Bias'] <- 
      coeff_lin$coefficients["z"]-ate
    
    
    ####################################
    # Kernel Regularized Least Squares #
    ####################################
    
    # All vars, including treatment, are splines
    fml <- 
      as.formula(
        paste("y ~",
              paste(paste(c("s(z,"),
                          paste(names(covs), collapse = ",")),
                    c(", bs = \"gKRLS\")"))))
    # Fit the model
    fit_gKRLS <- mgcv::gam(fml, data = data) 
    
    # Store result: Estimated through g-computation
    results[Estimator == 'G-comp:single:Krls' & 
              DGP == i & Simulation == j ,'Bias'] <- 
      calculate_effects(fit_gKRLS, variables = "z")$est-ate
    
    # Now fit separate models for each arm
    fml2 <- 
      as.formula(
        paste("y ~",
              paste(paste(c("s("), # No Z indicator, just covariates
                          paste(names(covs), collapse = ",")),
                    c(", bs = \"gKRLS\")"))))
    # Fit the model
    fit_gKRLSy1 <- mgcv::gam(fml2, data = subset(data, z==1)) 
    fit_gKRLSy0 <- mgcv::gam(fml2, data = subset(data, z==0))
    
    # Store result: g-computation
    results[Estimator == 'G-comp:cross:Krls' & 
              DGP == i & Simulation == j ,'Bias'] <- 
      (mean(predict.gam(fit_gKRLSy1, newdata = dataZ1[data$z==0,]))-
         mean(predict.gam(fit_gKRLSy0, newdata = dataZ0[data$z==1])))-ate
    
    
    ###################
    ### OUTCOME MODELS: SuperLearner
    ##################
    # Now move into the SL framework, combining multiple estimators
    
    #########
    # TASKS: Specify the tasks to be completed by the SuperLearner
    #########
    # For the SuperLearner, first define the tasks (common across iterations and DGPs)
    # Then train the models in each iteration
    
    # Single regression models (predict Y using covariates)
    task_y <- sl3_Task$new(
      data = data,
      outcome = "y",
      outcome_type = "continuous",
      covariates = c("z", names(covs)))
    
    # Separate regression models (predict Y0, Y1 using covariates)
    task_y0 <- sl3_Task$new(
      data = subset(data, z == 0),
      outcome = "y",
      outcome_type = "continuous",
      covariates = names(covs))
    
    task_y1 <- sl3_Task$new(
      data = subset(data, z == 1),
      outcome = "y",
      outcome_type = "continuous",
      covariates = names(covs))
    
    # PO imputation tasks (for single model, with Z included)
    task_y0hat <- sl3_Task$new(
      data = dataZ0,
      outcome = "y",
      covariates = c("z", names(covs)))  
    
    task_y1hat <- sl3_Task$new(
      data = dataZ1,
      outcome = "y",
      covariates = c("z", names(covs)))  
    
    # PO imputation tasks (for cross-fitted models)
    task_yxhat <- sl3_Task$new(
      data = data,
      outcome = "y",
      covariates = names(covs))  
    
    ######################
    # Instantiate learners to be used
    ######################
    
    # Mean model
    lrn_mean <- Lrnr_mean$new()
    
    # Unregularized linear model, main terms
    lrn_glm <- Lrnr_glm$new()
    
    # Regularized regression (lasso, elastic net, and ridge)
    lrn_lasso <- Lrnr_glmnet$new(alpha = 0)
    lrn_en025 <- Lrnr_glmnet$new(alpha = 0.25)
    lrn_en050 <- Lrnr_glmnet$new(alpha = 0.5)
    lrn_en075 <- Lrnr_glmnet$new(alpha = 0.75)
    lrn_ridge <- Lrnr_glmnet$new(alpha = 1)
    
    # Additional, more flexible learners
    lrn_pspl <- Lrnr_polspline$new() # polynomial splines
    lrn_earth <- Lrnr_earth$new() # multivariate adaptive regression splines
    # highly adaptive lasso (very slow! Take out)
    #lrn_hal <- Lrnr_hal9001$new() 
    
    # Tree-based methods
    lrn_ranger <- Lrnr_ranger$new()
    lrn_xgb <- Lrnr_xgboost$new()
    
    # Add some extra learners
    lrn_gam <- Lrnr_gam$new()
    lrn_bayesglm <- Lrnr_bayesglm$new()
    
    # Not working insider SL (Take out)
    #lrn_krls <- Lrnr_gam$new(fml1) 
    #lrn_krls2 <- Lrnr_gam$new(fml2) 
    #lrn_grf <- Lrnr_grf$new() 
    
    ########################
    # Create learners stack
    ########################
    
    stack <- Stack$new(
      "mean" = lrn_mean, "glm" = lrn_glm, 
      "lasso" = lrn_lasso, "ridge" = lrn_ridge,
      "en025" = lrn_en025, "en050" = lrn_en050, "en075" = lrn_en075, 
      "polspline" = lrn_pspl, "earth" = lrn_earth, 
      "ranger" = lrn_ranger, "xgboost" = lrn_xgb,
      "gam" = lrn_gam, "bglm" = lrn_bayesglm
    )
    
    #####################
    # Instantiate the meta-learners
    #####################
    
    # Non-negative least squares
    sl <- Lrnr_sl$new(learners = stack,
                      keep_extra = TRUE,
                      metalearner = Lrnr_nnls$new())
    
    #####################
    # Training the stack and meta-learner
    #####################
    
    # First: single model for the outcome
    start_time <- proc.time()
    
    sl_y <- sl$train(task = task_y)
    
    runtime <- proc.time() - start_time
    runtime
    
    # Then: cross-models for the outcome
    
    # For the treated
    start_time <- proc.time()
    sl_y1 <- sl$train(task = task_y1)
    runtime <- proc.time() - start_time
    runtime
    
    # For the controls
    start_time <- proc.time()
    sl_y0 <- sl$train(task = task_y0)
    runtime <- proc.time() - start_time
    runtime
    
    # Finally: obtaining predictions, g-computation
    # Both from the SL and also single learners inside the stack
    
    # Linear model, main terms
    results[Estimator == 'Coeff:Linear' & 
              DGP == i & Simulation == j ,'Bias'] <- 
      sl_y$learner_fits$glm$coefficients["z"]-ate
    
    # Predictions from SL: single model
    y1hat_sl <- sl_y$predict(task = task_y1hat)
    y0hat_sl <- sl_y$predict(task = task_y0hat)
    
    results[Estimator == 'G-comp:single:SL' & 
              DGP == i & Simulation == j ,'Bias'] <- 
      mean(y1hat_sl - y0hat_sl)-ate
    
    # Predictions for all obs
    mean(y1hat_sl - y0hat_sl)
    # Prediction for the missing PO only
    y1hat_sl_imp <- ifelse(data$z==1, data$y, y1hat_sl)
    y0hat_sl_imp <- ifelse(data$z==0, data$y, y0hat_sl)
    mean(y1hat_sl_imp - y0hat_sl_imp)
    
    # Predictions from SL: cross-models (working horribly! Check again)
    y1xhat_sl <- sl_y1$predict(task = task_yxhat)
    y0xhat_sl <- sl_y0$predict(task = task_yxhat)
    
    # Full sample: incorrect?
    mean(y1xhat_sl[data$z==0]-y0xhat_sl[data$z==1])
    # Predictions only in the complement
    mean(y1xhat_sl[data$z==0])-mean(y0xhat_sl[data$z==1])
    
    results[Estimator == 'G-comp:cross:SL' & 
              DGP == i & Simulation == j ,'Bias'] <- 
      mean(y1hat_sl - y0hat_sl)-ate
    
    yhat_sl <- sl_fit$predcit(task = task_y) # General SL predictions
    yhat_lasso <- sl_fit$learner_fits$Lrnr_glmnet_NULL_deviance_10_0_100_TRUE_FALSE$predict()
    
    ################################
    ### --- TREATMENT MODELS --- ### 
    ################################
    # Now let's focus in propensity score estimation
    
    # Task: Propensity score estimation (predict treatment given covariates)
    task_ps <- sl3_Task$new(
      data = data,
      outcome = "z",
      outcome_type = "binomial",
      covariates = names(covs)
    )
    
    
    ####################################
    ### --- AUGMENTED ESTIMATORS --- ### 
    ####################################
    
    # Generalized random forest : causal forest
    grf <- grf::causal_forest(X = model.matrix(~ 0 + ., covs), 
                              Y = data$y, W = data$z, num.trees = 4000)
    aipw_grf <- grf::average_treatment_effect(grf, target.sample = "all", method = "AIPW")
    tmle_grf <- grf::average_treatment_effect(grf, target.sample = "all", method = "TMLE")
    
    # Store results: AIPW and TMLE
    results[Estimator == 'DR:AIPW:grf' & 
              DGP == i & Simulation == j ,'Bias'] <- aipw_grf["estimate"]-ate
    
    results[Estimator == 'DR:TMLE:grf' & 
              DGP == i & Simulation == j ,'Bias'] <- tmle_grf["estimate"]-ate
    
    
    
    
    
    ###########################
    ##### TRAINING MODELS #####
    ###########################
    
    #sl_fit$learner_fits$glm$coefficients["z"]
    
    
  } # End iterations over realizations
  
} # End iterations over DGPs

```


We then specify the prediction tasks that are going to be used by the SuperLearner (`sl3` framework), so we can train the models across simulations.

```{r, eval=FALSE}
library(ggplot2)
results |> dplyr::filter(!is.na(Bias)) |> 
  ggplot(aes(y=Estimator, x=Bias)) +
  geom_boxplot() +
  geom_vline(xintercept = 0, color = "red", linetype = "dashed")+
  theme_bw()




#########
# TASKS: Specify the tasks to be completed by the SuperLearner
#########

# For the SuperLearner, first define the tasks (common across iterations and DGPs)
# Then train the models in each iteration

# Task: Propensity score estimation (predict treatment given covariates)
task_ps <- sl3_Task$new(
  data = data,
  outcome = "z",
  outcome_type = "binomial",
  covariates = names(covs)
)

# Single regression models (predict Y using covariates)
task_y <- sl3_Task$new(
  data = data,
  outcome = "y",
  outcome_type = "continuous",
  covariates = c("z", names(covs))
)

# Separate regression models (predict Y0, Y1 using covariates)
task_y0 <- sl3_Task$new(
  data = subset(data, z == 0),
  outcome = "y",
  outcome_type = "continuous",
  covariates = names(covs)
)

task_y1 <- sl3_Task$new(
  data = subset(data, z == 1),
  outcome = "y",
  outcome_type = "continuous",
  covariates = names(covs)
)

# PO imputation tasks (for single model, with Z included)
task_y0hat <- sl3_Task$new(
  data = dataZ0,
  covariates = c("z", names(covs))
)  

task_y1hat <- sl3_Task$new(
  data = dataZ1,
  covariates = c("z", names(covs))
)  

# PO imputation tasks (for cross-fitted models)
task_yxhat <- sl3_Task$new(
  data = data,
  covariates = names(covs)
)  
```

Now we can run the simulations
```{r, eval=FALSE}

###########################
### --- SIMULATIONS --- ### 
###########################

# Create empty list to store data
data <- list()

# Iterate over different DGPs 
# (1:20), corresponding to the do-it-yourself part of the competition
dgp <- 1:n_dgps

for(i in dgp){
  
  # Combine different simulations of same DGP
  # (1:100), keep sim identifier
  
  # First, capture the list of files to be used
  file_list <- 
    list.files(paste0(path,"1"), # Switch to the i later
               pattern = "*.csv", 
               ignore.case = TRUE,
               full.names = FALSE)
  
  for(j in file_list){
    
    data[[j]] <- data.table::fread(
      file = paste0(path,"1/",j)
    )[, sim_id := j] # Add identifier to data
    
  }
  
  # Combine the list into a single data frame
  data <- data.table::rbindlist(data)
  
  
}  

```

### Building blocks

```{r}
# Estimate the models to later compute treatment effects: 
# Propensity scores and outcome models

# First, combine outcome and covs in a single data
data <- cbind(outcomes, covs)
data <- data |> dplyr::mutate(y = ifelse(z==0, y0, y1))

# Then, benchmark estimates
ate <- mean(data$y1 - data$y0)
dim <- mean(data$y[data$z==1]) - mean(data$y[data$z==0])

# Then, for the SuperLearner, instante the models to be used

######################
# Instantiate learners to be used
######################

# Mean model
lrn_mean <- Lrnr_mean$new()

# Unregularized linear model, main terms
lrn_glm <- Lrnr_glm$new()

# Regularized regression (lasso, elastic net, and ridge)
lrn_lasso <- Lrnr_glmnet$new(alpha = 0)
lrn_en025 <- Lrnr_glmnet$new(alpha = 0.25)
lrn_en050 <- Lrnr_glmnet$new(alpha = 0.5)
lrn_en075 <- Lrnr_glmnet$new(alpha = 0.75)
lrn_ridge <- Lrnr_glmnet$new(alpha = 1)

# Additional, more flexible learners
lrn_pspl <- Lrnr_polspline$new() # polynomial splines
lrn_earth <- Lrnr_earth$new() # multivariate adaptive regression splines
#lrn_hal <- Lrnr_hal9001$new() # highly adaptive lasso (very slow!)

# Tree-based methods
lrn_ranger <- Lrnr_ranger$new()
lrn_xgb <- Lrnr_xgboost$new()
#lrn_grf <- Lrnr_grf$new() # Not working insider SL

# Add some extra learners
lrn_gam <- Lrnr_gam$new()
lrn_bayesglm <- Lrnr_bayesglm$new()

#lrn_krls <- Lrnr_gam$new(fml1) # Not working inside SL
#lrn_krls2 <- Lrnr_gam$new(fml2) # Not working inside SL

########################
# Create learners stack
########################

stack <- Stack$new(
  "mean" = lrn_mean, "glm" = lrn_glm, 
  "lasso" = lrn_lasso, "ridge" = lrn_ridge,
  "en025" = lrn_en025, "en050" = lrn_en050, "en075" = lrn_en075, 
  "polspline" = lrn_pspl, "earth" = lrn_earth, 
  "ranger" = lrn_ranger, "xgboost" = lrn_xgb,
  "gam" = lrn_gam, "bglm" = lrn_bayesglm
)

#####################
# Instantiate the meta-learners
#####################

# Non-negative least squares
sl <- Lrnr_sl$new(learners = stack,
                  keep_extra = TRUE,
                  metalearner = Lrnr_nnls$new()
)

######################
## Propensity score ##
######################

# Estimators outside the SL: lin, grf, kernel(?)

# KRLS pending until I figure this out
# Lin not sure it makes sense for pscore

set.seed(24500-03)
start_time <- proc.time()

sl_fit <- sl$train(task = task_y)

runtime <- proc.time() - start_time
runtime

# Obtaining predictions from the stack and SL

yhat_sl <- sl_fit$predcit(task = task_y) # General SL predictions
yhat_lasso <- sl_fit$learner_fits$Lrnr_glmnet_NULL_deviance_10_0_100_TRUE_FALSE$predict()


####################
## Outcome models ##
####################

# Linear regression

y0_lm <- ()
y1_lm <- ()

y0_lin <- ()
y1_lin <- ()

# LASSO

y0_lasso
y1_lasso

# Random forest

y0_grf
y1_grf

# Kernel regression

y0_krls
y1_krls



##########################
### --- ESTIMATORS --- ###
##########################

#############################
## Regression Coefficients ##
#############################

###################
## G-Computation ##
###################

##############
## Matching ##
##############

###############
## Weighting ##
###############

###########################
## Augmented  estimators ##
###########################

# Augmented-IPW

# TMLE

# DML

#################################
## Prognostic Propensity score ##
#################################

# PPS-Matching (logit/lasso/forest/krls)

# PPS-Weighting (logit/lasso/forest/krls)

# Y0-weighting (logit/lasso/forest/krls)

}
```

### Propensity score

```{r}
caca
```


### Outcome models

```{r}
caca
```


### Treatment effect estimation

```{r}
# The estimators we are going to test are the following
# Balance covariate alone: IPW, PS-matching, Ebal, Tfbal
# Outcome model alone: Linear regression, Lin, GRF, Kbal
# DR models: AIPW, TMLE, DML
# Proposed estimators: 
# 1) Prognostic Balance (E(Y0))
# 2) Prognostic Propensity Score (E(D|Y0)) Balance
# 3) Prognostic 


fit_gKRLS1 <- mgcv::gam(fml1, data = data)
calculate_effects(fit_gKRLS1, variables = "z")
fit_gKRLS2 <- mgcv::gam(fml2, data = data)
calculate_effects(fit_gKRLS2, variables = "z")

# DR: Generalized random forest : causal forest
grf <- causal_forest(X = data[covs], Y = data$y, W = data$z)
aipw_grf <- average_treatment_effect(grf, target.sample = "all", method = "AIPW")
tmle_grf <- average_treatment_effect(grf, target.sample = "all", method = "TMLE")

# Save table with missing cases
data.table::fwrite(data,
                   file = paste0(path_results, "/table_data.csv"),
                   append = TRUE)

```
